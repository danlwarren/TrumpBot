palin.ngram <- ngram(diarrhea.in, 2)
head(diarrhea.in)
palin.ngram <- ngram(diarrhea.in, 2)
findOffendingCharacter <- function(x){
#print(x)
for (c in 1:nchar(x)){
offendingChar <- substr(x,c,c)
print(offendingChar) #uncomment if you want the indiv characters printed
#the next character is the offending multibyte Character
}
}
lapply(diarrhea.in, findOffendingCharacter)
findOffendingCharacter <- function(x){
print(x)
for (c in 1:nchar(x)){
offendingChar <- substr(x,c,c)
print(offendingChar) #uncomment if you want the indiv characters printed
#the next character is the offending multibyte Character
}
}
lapply(diarrhea.in, findOffendingCharacter)
infile <- file("palin.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("palintweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
palin.ngram <- ngram(diarrhea.in, 2)
infile <- file("palin.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("palintweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
palin.ngram <- ngram(diarrhea.in, 2)
while(1){
palin.babble <- babble(palin.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", palin.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(palin.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
out.sentence <- sample(sentences, 1)
print(out.sentence)
#tweet(out.sentence)
Sys.sleep(3)
}
setwd("~/GitHub/PalinBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "ff6Jf9V7epy27yMbNJuDVvJun"
apisecret <- "Jzgju26tWFvoOjpKf6TiSsYgqWjHWOUQe4nKVmcCsBIg4VL5zu"
token <- "4837743903-demnJz0lwa5DHQqnoqOx04DNRiXPBys4WFqB3HY"
tokensecret <- "cDloocuGYiNwIlfaUJuqu5A5HptxBjY3r7vNPFfzpytgc"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("palin.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("palintweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
palin.ngram <- ngram(diarrhea.in, 2)
while(1){
palin.babble <- babble(palin.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", palin.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(palin.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
out.sentence <- sample(sentences, 1)
print(out.sentence)
#tweet(out.sentence)
Sys.sleep(5)
}
setwd("~/GitHub/PalinBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "ff6Jf9V7epy27yMbNJuDVvJun"
apisecret <- "Jzgju26tWFvoOjpKf6TiSsYgqWjHWOUQe4nKVmcCsBIg4VL5zu"
token <- "4837743903-demnJz0lwa5DHQqnoqOx04DNRiXPBys4WFqB3HY"
tokensecret <- "cDloocuGYiNwIlfaUJuqu5A5HptxBjY3r7vNPFfzpytgc"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("palin.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("palintweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
palin.ngram <- ngram(diarrhea.in, 2)
while(1){
palin.babble <- babble(palin.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", palin.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(palin.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
#tweet(out.sentence)
}
Sys.sleep(5)
}
setwd("~/GitHub/PalinBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "ff6Jf9V7epy27yMbNJuDVvJun"
apisecret <- "Jzgju26tWFvoOjpKf6TiSsYgqWjHWOUQe4nKVmcCsBIg4VL5zu"
token <- "4837743903-demnJz0lwa5DHQqnoqOx04DNRiXPBys4WFqB3HY"
tokensecret <- "cDloocuGYiNwIlfaUJuqu5A5HptxBjY3r7vNPFfzpytgc"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("palin.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("palintweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
palin.ngram <- ngram(diarrhea.in, 2)
while(1){
palin.babble <- babble(palin.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", palin.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(palin.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
#tweet(out.sentence)
}
Sys.sleep(5)
}
head(palin.ngram)
palin.ngram
names(palin.ngram)
attributes(palin.ngram)
setwd("~/GitHub/PalinBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
help(searchTwitter)
sarah.tweets <- twListToDF(userTimeline('realDonaldTrump', n=3200))$text
setwd("~/GitHub/PalinBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
trump.tweets <- twListToDF(userTimeline('realDonaldTrump', n=3200))$text
trump.tweets
# Function to strip off trailing ... and url from fb posts
strip.fb <- function(x){
this.tweet <- gsub('\\.\\.\\..*', "", x)
this.tweet <- gsub('http.*', "", this.tweet)
}
new.tweets <- c()
for(i in trump.tweets){
new.tweets <- c(new.tweets, strip.fb(i))
}
write(new.tweets, file="trumptweets.txt")
# NOTE: You need to re-encode these in Sublime to UTF-8
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
#tweet(out.sentence)
}
Sys.sleep(3)
}
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(30)
}
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(30)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(30)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(30)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(300)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(300)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(300)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(300)
}
setwd("~/GitHub/TrumpBot")
library(ngram)
library(twitteR)
options(httr_oauth_cache=T)
apikey <- "fD92z0TeeisqolZDIOxN6bhc1"
apisecret <- "cx2weAt8Xg17IBSdfc6UPuxCBBw2Cf7MjSPjIyd0iPNH8GwxVD"
token <- "4805050178-bHyM5ZfP2u7NMXECZ5j7IVd79463kZpEPZlb2ru"
tokensecret <- "W3PY7YIsz9fJw5B5PJ6cF93fVp3uuJqP4mRmuEgV1nWyz"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("trump.txt")
diarrhea.in <- readLines(infile)
infile2 <- file("trumptweets.txt")
tweets.in <- readLines(infile2)
diarrhea.in <- c(diarrhea.in, tweets.in)
diarrhea.in <- paste(diarrhea.in, collapse = " ")
trump.ngram <- ngram(diarrhea.in, 2)
while(1){
trump.babble <- babble(trump.ngram)
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", trump.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(trump.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
tweet(out.sentence)
}
Sys.sleep(300)
}
